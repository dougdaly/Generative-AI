# ğŸ§  GenAI Demos Portfolio

This repository contains a collection of demos showcasing **Generative AI techniques**.  
The notebooks are built with the latest Python libraries, support multiple GPU providers, and include references and explanations where relevant.  

ğŸ‘‰ The goal: demonstrate practical implementations of GenAI concepts â€” from **image generation** to **multi-modal AI** â€” in a way that is both educational and extensible.  

---

## ğŸ“‚ Contents & Topics

### ğŸ”¹ Multi-Agent Workflows (LangGraph / LangChain)
- **mtg-card-generator.ipynb** â†’ shows the benefits of using multiple agents for a complex task: building new creature cards for a popular trading card game (Magic: The Gathering)
- **langGraph-multi-agent-workflow.ipynb** â†’ combines a search agent + image generation agent (OpenAI) to generate a grid of famous athletes by country.  
- **langGraph-alphabet.ipynb** â†’ creates an AI-powered childrenâ€™s alphabet poster with words + images.  

### ğŸ”¹ GANs (Generative Adversarial Networks)
- **GAN_demo.ipynb** â†’ trains a GAN on a celebrity dataset, demonstrating generator vs discriminator competition and pitfalls of the approach.  

### ğŸ”¹ CLIP (Contrastive Languageâ€“Image Pretraining)
- **CLIP-from-ground-up.ipynb** â†’ builds a CLIP model from scratch on Flickr dataset (images + captions).  
- **CLIP_tuning.ipynb** â†’ fine-tunes a CLIP model for domain-specific tasks (example: aerial imagery).  

### ğŸ”¹ Retrieval-Augmented Generation (RAG)
- **Building_a_multimodal_RAG.ipynb** â†’ queries both stored text and images with multimodal input.  

### ğŸ”¹ Diffusion Models
- **annotated_diffusion.ipynb** â†’ step-by-step theory & math of progressive noise addition with MNIST fashion dataset.  
- **score_based_diffusion.ipynb** â†’ implements score-based diffusion with ODE solver.  
- **Stable_Diffusion.ipynb** â†’ uses HuggingFace diffusion models with CLIP text encoder for text-to-image generation.  

### ğŸ”¹ Stability.ai API
- **Stability_API_Demo.ipynb** â†’ demonstrates masking, overlaying, background replacement, and other image-editing tasks via Stability.ai API.  

### ğŸ”¹ Variational Autoencoders (VAE)
- **VAE_Example.ipynb** â†’ compares a standard autoencoder vs a variational autoencoder to explain the power of VAEs.  

---

## ğŸš€ Tech Stack
- **Python** (latest libraries)  
- **PyTorch / HuggingFace / LangChain / LangGraph**  
- **Diffusion, GANs, CLIP, RAG, VAEs**  
- **APIs**: Stability.ai, OpenAI  

---

## ğŸ“Š Results
Sample outputs are stored in the `results/` folder.  
> ğŸ” These are not required to run the demos â€” they simply illustrate recent experiments.

---

## ğŸ§© How to Use
1. Clone the repo:
   ```bash
   git clone https://github.com/your-username/genai-demos.git
